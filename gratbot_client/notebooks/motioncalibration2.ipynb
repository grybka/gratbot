{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../to_study/initial_chase_calib.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-617ace5036d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mfirst_timestamp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_timestamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msensor_log\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_timestamp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_sensor_log_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../to_study/initial_chase_calib.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-617ace5036d5>\u001b[0m in \u001b[0;36mload_sensor_log_file\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mfirst_timestamp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../to_study/initial_chase_calib.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "    \n",
    "def dict_array_upend(mydict,key,elem):\n",
    "    if key not in mydict:\n",
    "        mydict[key]=[]\n",
    "    mydict[key.append(elem)]\n",
    "\n",
    "def load_sensor_log_file(fname):\n",
    "    response=[]\n",
    "    first_timestamp=0\n",
    "    f=open(fname,'r')\n",
    "    for line in f.readlines():        \n",
    "        dat=json.loads(line)\n",
    "        timestamp=dat[\"timestamp\"]-first_timestamp\n",
    "        response.append(dat)\n",
    "        if first_timestamp==0:                        \n",
    "            first_timestamp=timestamp\n",
    "    return response,first_timestamp\n",
    "sensor_log,first_timestamp=load_sensor_log_file(\"../to_study/initial_chase_calib.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset,random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "gyro_t=[]\n",
    "gyro=[]\n",
    "\n",
    "#NN1 - outcome predictor\n",
    "#inputs: motion magnitude, motion time, object position\n",
    "#outputs: new object position\n",
    "\n",
    "#NN2 - input predictor\n",
    "#inputs: old object position, new object position\n",
    "#outputs: motion magnitude, motion time\n",
    "\n",
    "class VisualMotionDataset:\n",
    "    def __init__(self):\n",
    "        #objects to track\n",
    "        self.objects_to_watch=[\"sports ball\",\"stop sign\",\"chair\"]\n",
    "        \n",
    "        #defs of what goes where\n",
    "        self.command_predictor_input_size=2\n",
    "        self.command_predictor_output_size=3\n",
    "        self.motion_predictor_input_size=4\n",
    "        self.motion_predictor_output_size=1\n",
    "        \n",
    "        #scales of things\n",
    "        self.position_scale=640\n",
    "\n",
    "        #the accumulated data\n",
    "        self.command_predictor_dataset_inputs=[]\n",
    "        self.command_predictor_dataset_targets=[]\n",
    "        self.motion_predictor_dataset_inputs=[]                \n",
    "        self.motion_predictor_dataset_targets=[]                \n",
    "        \n",
    "        #last frame data \n",
    "        self.wait_after_motion_time=0.1\n",
    "        self.last_motion_time=0\n",
    "        self.gyro_stable_frame=False\n",
    "        self.motor_stable_frame=False\n",
    "        self.last_frame_tagged_objects=[]\n",
    "        self.last_frame_motion_command=[]\n",
    "        \n",
    "    def produce_motion_predictor_dataset(self):\n",
    "        return TensorDataset(torch.tensor(self.motion_predictor_dataset_inputs),torch.tensor(self.motion_predictor_dataset_targets))\n",
    "            \n",
    "                    \n",
    "    def construct_tagged_object_info(self,tagged_objects):\n",
    "        #return tag info for all objects for which only one is in list\n",
    "        ret={}\n",
    "        labels=[ x[\"label\"] for x in tagged_objects ]        \n",
    "        for obj in tagged_objects:\n",
    "            label=obj[\"label\"]\n",
    "            if labels.count(label)==1:\n",
    "                ret[label]=obj\n",
    "        return ret\n",
    "    \n",
    "    def parse_message(self,message):\n",
    "        if \"position_sensor/gyro\" in message:\n",
    "            m=message[\"position_sensor/gyro\"]\n",
    "            gyro_z=message[\"position_sensor/gyro\"][2]\n",
    "            gyro_z_stdev=message[\"position_sensor/gyro_stdev\"][2]            \n",
    "            if abs(gyro_z)>0.05 or gyro_z_stdev>0.05:\n",
    "                self.gyro_stable_frame=False                \n",
    "            else:\n",
    "                self.gyro_stable_frame=True\n",
    "        if \"drive/motors_active\" in message:\n",
    "            m=message[\"drive/motors_active\"]\n",
    "            if m[0]!=0 or m[1]!=0:\n",
    "                self.motor_stable_frame=False\n",
    "            else:\n",
    "                self.motor_stable_frame=True\n",
    "                \n",
    "        if \"motor_command\" in message:\n",
    "            m=message[\"motor_command\"]\n",
    "            if m[\"lr_throttle\"][0] or m[\"lr_throttle\"][1]!=0:\n",
    "                self.last_motion_time=message[\"timestamp\"]\n",
    "                self.last_frame_motion_command=[ m[\"lr_throttle\"][0],m[\"lr_throttle\"][1],m[\"duration\"]]\n",
    "            \n",
    "                \n",
    "                \n",
    "        if \"tagged_objects\" in message:\n",
    "            if (not self.gyro_stable_frame) or (not self.motor_stable_frame) or (message[\"timestamp\"]-self.last_motion_time<self.wait_after_motion_time):\n",
    "                #print(\"unstable {} {} {}\".format(self.gyro_stable_frame,self.motor_stable_frame,message[\"timestamp\"]-self.last_motion_time))\n",
    "                return #unstable frame, don't trust object tagger\n",
    "            #print(\"stable {} {} {}\".format(self.gyro_stable_frame,self.motor_stable_frame,message[\"timestamp\"]-self.last_motion_time))\n",
    "            tagged_objects=self.construct_tagged_object_info(message[\"tagged_objects\"])\n",
    "            #print(\"n tagged objects {}\".format(len(tagged_objects)))\n",
    "            for key in tagged_objects:\n",
    "                if key not in self.last_frame_tagged_objects:\n",
    "                    continue\n",
    "                prev_startx=self.last_frame_tagged_objects[key][\"startx\"]\n",
    "                prev_endx=self.last_frame_tagged_objects[key][\"endx\"]\n",
    "                prev_x=0.5*(prev_startx+prev_endx)\n",
    "                next_startx=tagged_objects[key][\"startx\"]\n",
    "                next_endx=tagged_objects[key][\"endx\"]\n",
    "                next_x=0.5*(next_startx+next_endx)\n",
    "                self.motion_predictor_dataset_inputs.append( [prev_x/self.position_scale, *self.last_frame_motion_command ])\n",
    "                self.motion_predictor_dataset_targets.append([ next_x/self.position_scale ])\n",
    "                self.command_predictor_dataset_inputs.append( [prev_x/self.position_scale, next_x/self.position_scale])\n",
    "                self.command_predictor_dataset_targets.append([ *self.last_frame_motion_command ] )\n",
    "            self.last_frame_tagged_objects=tagged_objects           \n",
    "            self.last_frame_motion_command=[0,0,0]\n",
    "               \n",
    "myset=VisualMotionDataset()\n",
    "for message in sensor_log:\n",
    "    myset.parse_message(message)\n",
    "    #t=message[\"timestamp\"]-first_timestamp\n",
    "    \n",
    "#print(\"motion-predictor size {}\".format(len(myset.motion_predictor_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "hidden_size=4\n",
    "motion_predictor=nn.Sequential(nn.Linear(myset.motion_predictor_input_size,hidden_size),\n",
    "                               nn.Tanh(),\n",
    "                               nn.Linear(hidden_size,myset.motion_predictor_output_size))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=myset.produce_motion_predictor_dataset()\n",
    "train_fraction=0.5\n",
    "train_size=int(train_fraction*len(dataset))\n",
    "test_size=len(dataset)-train_size\n",
    "train_dataset,test_dataset=random_split(dataset,[train_size,test_size])\n",
    "\n",
    "pows=[]\n",
    "truths=[]\n",
    "for x,y in test_dataset:\n",
    "    pows.append( x[1].detach().numpy() )    \n",
    "    truths.append( (y[0]-x[0]).detach().numpy())\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(truths,pows,'*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "device = torch.device('cpu') \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "def train_model_step(model,optimizer,inputs,targets):    \n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    out=model( inputs) \n",
    "    loss=loss_function(out,targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test_model_step(model,inputs,targets):    \n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    out=model( inputs) \n",
    "    loss=loss_function(out,targets)   \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train_thing(model,train_dataloader,test_dataloader):\n",
    "    # Loop over epochs\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_loss_log=[]\n",
    "    test_loss_log=[]\n",
    "    max_epochs=1000\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        # Training\n",
    "        train_loss_sum=0\n",
    "        counter=0\n",
    "        for input_batch,target_batch in train_dataloader:\n",
    "            #print(\"state batch shape {}\".format(state_batch.shape))\n",
    "            #print(\"command batch shape {}\".format(command_batch.shape))\n",
    "            #print(\"predict batch shape {}\".format(result_batch.shape))\n",
    "            # Transfer to GPU\n",
    "            input_batch,target_batch=input_batch.to(device), target_batch.to(device)                                          \n",
    "            train_loss_sum+=train_model_step(model,optimizer,input_batch,target_batch)\n",
    "            counter+=1\n",
    "        train_loss_log.append(train_loss_sum/counter)\n",
    "    \n",
    "        test_loss_sum=0\n",
    "        counter=0\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for input_batch, target_batch in test_dataloader:            \n",
    "                # Transfer to GPU                \n",
    "                input_batch, target_batch=input_batch.to(device), target_batch.to(device)                                                             \n",
    "                test_loss_sum+=test_model_step(model,input_batch,target_batch)                \n",
    "                counter+=1\n",
    "        test_loss_log.append(test_loss_sum/counter)\n",
    "    return train_loss_log,test_loss_log\n",
    "    \n",
    "train_loss_log,test_loss_log=train_thing(motion_predictor,train_dataloader,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Loss\")\n",
    "ax.plot(np.log(train_loss_log),label=\"training\")\n",
    "ax.plot(np.log(test_loss_log),label=\"testing\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "preds=[]\n",
    "truths=[]\n",
    "pows=[]\n",
    "for x,y in test_dataset:\n",
    "    yprime=(motion_predictor(torch.unsqueeze(x,0)))[0]\n",
    "    pows.append( x[1].detach().numpy() )    \n",
    "    preds.append( (yprime[0]-x[0]).detach().numpy())\n",
    "    truths.append( (y[0]-x[0]).detach().numpy())\n",
    "    \n",
    "preds=np.array(preds)\n",
    "truths=np.array(truths)\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(truths)\n",
    "#ax.plot(preds)\n",
    "ax.plot(pows,truths,'*')\n",
    "ax.plot(pows,preds,'*')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(pows,truths-preds,'*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on each action\n",
    "\n",
    "# did my predictor predict the outcome well?  -> pred_err\n",
    "# did my action inference infer the correct action -> act_err\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
